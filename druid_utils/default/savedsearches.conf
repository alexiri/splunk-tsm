
# Populating lookup tables

[lookup_serverinfo]
dispatch.earliest_time = -7d
dispatch.latest_time = now
cron_schedule = */5 * * * *
enableSched = 1
is_visible = false
action.populate_lookup = 1
action.populate_lookup.dest = serverinfo
run_on_startup = true
search = `lastdb("status")` | join type=outer host [search index=sysinfo host_fc | stats values(host_wwns) AS HOST_WWNS by host | eval HOST_WWNS=mvjoin(HOST_WWNS, " ") | fields host HOST_WWNS] | eval SERVER_VERSION=VERSION+"."+RELEASE+"."+LEVEL+"."+SUBLEVEL | rename SERVER_NAME AS TSMSERVER host AS HOST | append [| inputlookup serverinfo ] | stats first(HOST) AS HOST first(SERVER_VERSION) AS SERVER_VERSION first(SERVER_TYPE) AS SERVER_TYPE first(SERVER_STATUS) AS SERVER_STATUS first(BUILDING) AS BUILDING first(USAGE) AS USAGE first(COMMENT) AS COMMENT first(HOST_WWNS) AS HOST_WWNS by TSMSERVER | table TSMSERVER HOST SERVER_VERSION SERVER_TYPE SERVER_STATUS BUILDING USAGE COMMENT HOST_WWNS

[lookup_driveinfo]
dispatch.earliest_time = -48h
dispatch.latest_time = now
cron_schedule = */5 * * * *
enableSched = 1
is_visible = false
action.populate_lookup = 1
action.populate_lookup.dest = driveinfo
run_on_startup = true
search = `lastdb("drives")` | join type=outer DRIVE_SERIAL [search index=sysinfo drive_fc | stats values(drive_wwn) AS DRIVE_WWNS by drive_serial | eval DRIVE_WWNS=mvjoin(DRIVE_WWNS, " ") | rename drive_serial AS DRIVE_SERIAL | fields DRIVE_SERIAL DRIVE_WWNS] | table DRIVE_NAME LIBRARY_NAME ONLINE DRIVE_SERIAL DRIVE_WWNS ELEMENT

[lookup_nodeinfo]
dispatch.earliest_time = -7d
dispatch.latest_time = now
cron_schedule = */5 * * * *
enableSched = 1
is_visible = false
action.populate_lookup = 1
action.populate_lookup.dest = nodeinfo
run_on_startup = true
search = `lastdb("nodes")` | eval CONTACT=lower(CONTACT) | eval VERSION=CLIENT_VERSION+"."+CLIENT_RELEASE+"."+CLIENT_LEVEL+"."+CLIENT_SUBLEVEL | dedup tsmserver NODE_NAME | fillnull value="x" DEL_TIME | fillnull value="" PLATFORM_NAME CONTACT VERSION OPTION_SET COLLOCGROUP_NAME | eval PWSET_TIME=strptime(PWSET_TIME, "%Y-%m-%d %H:%M:%S.%6N") | eval LASTACC_TIME=strptime(LASTACC_TIME, "%Y-%m-%d %H:%M:%S.%6N") | eval REG_TIME=strptime(REG_TIME, "%Y-%m-%d %H:%M:%S.%6N") | append [|inputlookup nodeinfo | eval DEL_TIME=if(isnull(DEL_TIME) OR DEL_TIME=="", now(), DEL_TIME) | fillnull value="YES" ALERTS_DEFAULT | fillnull value="1" BACKUP_CYCLE ] | stats first(PLATFORM_NAME) AS PLATFORM_NAME first(DOMAIN_NAME) AS DOMAIN_NAME first(eval(strftime(PWSET_TIME, "%s"))) AS PWSET_TIME first(CONTACT) AS CONTACT first(LOCKED) AS LOCKED first(eval(strftime(LASTACC_TIME, "%s"))) AS LASTACC_TIME first(eval(strftime(REG_TIME, "%s"))) AS REG_TIME first(VERSION) AS VERSION first(NODETYPE) AS NODETYPE first(MAX_MP_ALLOWED) AS MAX_MP_ALLOWED first(OPTION_SET) AS OPTION_SET first(COLLOCGROUP_NAME) AS COLLOCGROUP_NAME first(REPL_STATE) AS REPL_STATE first(REPL_MODE) AS REPL_MODE first(USER_GROUP) AS USER_GROUP first(USER_SUBGROUP) AS USER_SUBGROUP list(DEL_TIME) AS DEL_TIME first(eval(strftime(RETIRE_TIME, "%s"))) AS RETIRE_TIME first(RETIRE_COMMENT) AS RETIRE_COMMENT first(eval(strftime(EXPIRE_TIME, "%s"))) AS EXPIRE_TIME first(BACKUP_CYCLE) AS BACKUP_CYCLE first(ALERTS_DEFAULT) AS ALERTS_DEFAULT by tsmserver, NODE_NAME | eval DEL_TIME=if(mvcount(DEL_TIME)>1, NULL, DEL_TIME) | table tsmserver NODE_NAME USER_GROUP USER_SUBGROUP RETIRE_TIME RETIRE_COMMENT EXPIRE_TIME PLATFORM_NAME DOMAIN_NAME PWSET_TIME CONTACT LOCKED LASTACC_TIME REG_TIME VERSION NODETYPE MAX_MP_ALLOWED OPTION_SET COLLOCGROUP_NAME REPL_STATE REPL_MODE DEL_TIME BACKUP_CYCLE ALERTS_DEFAULT

[lookup_contactinfo]
dispatch.earliest_time = -15m
dispatch.latest_time = now
cron_schedule = */30 * * * *
enableSched = 1
is_visible = false
action.populate_lookup = 1
action.populate_lookup.dest = contactinfo
run_on_startup = true
search = | inputlookup nodeinfo | eval contact=lower(CONTACT) | dedup contact | lookup ldaplookup contact OUTPUT username | mvexpand username | lookup ldaplookup username OUTPUT department group name | fillnull value="" department,group | eval dg=department+","+group | eval f=username+","+name+","+department+","+group | stats list(f) AS users mode(dg) AS dg by contact | mvexpand users | eval username=mvindex(split(users, ","), 0) | eval name=mvindex(split(users, ","), 1) | eval user_dept=mvindex(split(users, ","), 2) | eval user_group=mvindex(split(users, ","), 3) | eval contact_dept=mvindex(split(dg, ","), 0) | eval contact_group=mvindex(split(dg, ","), 1) | fields - users dg

[lookup_tapevolumeinfo]
dispatch.earliest_time = -7d
dispatch.latest_time = now
cron_schedule = 5 * * * *
enableSched = 1
is_visible = false
action.populate_lookup = 1
action.populate_lookup.dest = tapevolumeinfo
run_on_startup = true
search = `lastdb("libvolumes")` | rename STATUS AS LV_STATUS tsmserver AS lv_tsmserver | join type=outer VOLUME_NAME [search `lastdb("volumes")`] | eval tsmserver=if(LAST_USE=="DbBackup" OR LAST_USE=="DbDump" OR LAST_USE=="Export", OWNER, coalesce(tsmserver, OWNER, lv_tsmserver)) | eval STGPOOL=if(LAST_USE=="DbBackup" OR LAST_USE=="DbDump" OR LAST_USE=="Export", LAST_USE, if(isnull(STGPOOL_NAME) AND LV_STATUS=="Scratch", "Scratch", STGPOOL_NAME)) | eval SCRATCH=if(LV_STATUS=="Scratch" OR SCRATCH=="YES", "YES", "NO") | eval USED_MB=CASE(isnotnull(STGPOOL_NAME), PCT_UTILIZED/100*EST_CAPACITY_MB) | eval EST_CAPACITY_MB=if(isnotnull(EST_CAPACITY_MB) AND EST_CAPACITY_MB!=0, EST_CAPACITY_MB, CASE(MEDIATYPE=="3592-1", 655360, MEDIATYPE=="3592-2", 1677721, MEDIATYPE=="3592-3", 4194304, MEDIATYPE=="3592-4", 10485760, MEDIATYPE=="*", 10485760)) | table VOLUME_NAME tsmserver LIBRARY_NAME STGPOOL SCRATCH MEDIATYPE EST_CAPACITY_MB PCT_UTILIZED USED_MB ACCESS LV_STATUS STATUS ERROR_STATE LAST_READ_DATE LAST_WRITE_DATE READ_ERRORS WRITE_ERRORS TIMES_MOUNTED

[lookup_tapevolumehistory]
dispatch.earliest_time = 0
dispatch.latest_time = now
cron_schedule = 10 9 * * *
enableSched = 1
is_visible = false
action.populate_lookup = 1
action.populate_lookup.dest = tapevolumehistory
run_on_startup = true
search = index=tsmlogs tsmserver=tsmlib* tsmcode=ANR8468I | stats count as mounts latest(_time) AS last_mount earliest(_time) AS first_mount by tapevolume | append [| inputlookup tapevolumeinfo | rename VOLUME_NAME AS tapevolume] | stats values(mounts) AS mounts values(last_mount) AS last_mount values(first_mount) AS first_mount values(LIBRARY_NAME) AS library_name by tapevolume | search library_name=*

[lookup_scheduleinfo]
dispatch.earliest_time = -48h
dispatch.latest_time = now
cron_schedule = 15 8 * * *
enableSched = 1
is_visible = false
action.populate_lookup = 1
action.populate_lookup.dest = scheduleinfo
run_on_startup = true
search = `lastdb("associations")` | join tsmserver DOMAIN_NAME SCHEDULE_NAME [search `lastdb("client_schedules")`] | table tsmserver NODE_NAME DOMAIN_NAME SCHEDULE_NAME ACTION DAYOFWEEK DURATION DURUNITS OBJECTS OPTIONS PERIOD PERUNITS STARTDATE STARTTIME

[lookup_schedulestatus]
dispatch.earliest_time = -48h
dispatch.latest_time = now
cron_schedule = 15 8 * * *
enableSched = 1
is_visible = false
action.populate_lookup = 1
action.populate_lookup.dest = schedulestatus
run_on_startup = true
search = STATUS!="Future" NODE_NAME=* `tsmdb("events")` | eval SCHEDULED_START=round(strptime(SCHEDULED_START, "%F %T.%6Q")) | eval _time=SCHEDULED_START | eval start_time=round(strptime(ACTUAL_START, "%F %T.%6Q")) | eval end_time=round(strptime(COMPLETED, "%F %T.%6Q")) | eval status_time=_time | rename NODE_NAME AS node DOMAIN_NAME AS domain SCHEDULE_NAME AS schedule SCHEDULED_START AS scheduled_start_time STATUS AS status | rename RESULT AS result | rename REASON AS reason | stats latest(scheduled_start_time) AS scheduled_start_time latest(start_time) AS start_time latest(end_time) AS end_time latest(status_time) AS status_time latest(result) AS result latest(reason) AS reason by tsmserver node domain schedule status | append [| inputlookup schedulestatus] | sort -scheduled_start_time | dedup tsmserver node domain schedule status


# Update DNS records

[db_zone_backup]
dispatch.earliest_time = -7d
dispatch.latest_time = now
cron_schedule = */15 * * * *
enableSched = 1
is_visible = false
run_on_startup = true
search = `tsmdb("nodes")` | head (_time > now()-1200) | head 1 | map search="search `lastdb(\"nodes\")` | search REPL_MODE!=RECEIVE | sort LOCKED, -REG_TIME | stats first(tsmserver) AS tsmserver by NODE_NAME | eval DOMAIN=\".CERN.CH\" | append [| dbquery TSMMS \"TRUNCATE TABLE ZONE_BACKUP\"] | dboutput type=insert database=TSMMS table=ZONE_BACKUP NODE_NAME AS ALIAS tsmserver AS NAME DOMAIN | append [| updatedns]"
# The ... | head (_time > now()-900) | head 1 | map ... stuff is there so the rest of the search is only
# run if we have updated nodes in the last 120s (ie. 20m)


# Alert if DNS records aren't up-to-date
[DNS records not updated]
is_visible = false
action.email.inline = 1
action.script = 1
action.script.filename = alert.py
alert.severity = 4
alert.suppress = 0
alert.track = 1
cron_schedule = 0 9 * * *
dispatch.earliest_time = -7d
dispatch.latest_time = now
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
search = | dbquery "TSMMS" "SELECT SERIAL, UPDATED FROM DNS_ATTR" | appendcols [| dbquery "TSMMS" "SELECT count(*) AS NODES_DNS FROM ZONE_BACKUP"] | appendcols [search `lastdb("nodes")` | stats dc(NODE_NAME) AS NODES_TSMDB] | eval age=(now()-UPDATED)/86400 | eval "Last Update"=strftime(UPDATED, "%F %T") | eval "ok"=if('NODES_DNS'=='NODES_TSMDB' AND age<1, "yes", "no") | search ok=no

# Alert if DBX isn't working
[DBX connection not working]
is_visible = false
action.email.inline = 1
action.script = 1
action.script.filename = alert.py
alert.severity = 4
alert.suppress = 0
alert.track = 1
cron_schedule = 0 9 * * *
dispatch.earliest_time = -7d
dispatch.latest_time = now
enableSched = 1
counttype = number of events
relation = not equal to
quantity = 1
search = | dbquery "TSMMS" "SELECT SERIAL, UPDATED FROM DNS_ATTR"


# Update E-groups

[update_egroups]
dispatch.earliest_time = -7d
dispatch.latest_time = now
dispatch.ttl = 86400
cron_schedule = */15 * * * *
enableSched = 1
is_visible = false
run_on_startup = true
search = `tsmdb("nodes")` | head (_time > now()-1200) | head 1 | map search="search `lastdb(\"nodes\")` | lookup serverinfo TSMSERVER AS tsmserver OUTPUTNEW BUILDING SERVER_TYPE SERVER_STATUS | search SERVER_STATUS=production SERVER_TYPE=user CONTACT!=tsm-admin CONTACT!=tsm.support | dedup tsmserver CONTACT BUILDING | table tsmserver CONTACT BUILDING | updateegroups init=true fill=true"

# Alert if egroups aren't up to date
[E-groups not updated]
is_visible = false
action.email.inline = 1
action.script = 1
action.script.filename = alert.py
alert.severity = 4
alert.suppress = 0
alert.track = 1
cron_schedule = 0 9 * * *
dispatch.earliest_time = -7d
dispatch.latest_time = now
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
search = `lastdb("nodes")` | lookup serverinfo TSMSERVER AS tsmserver OUTPUTNEW BUILDING SERVER_TYPE SERVER_STATUS | search SERVER_STATUS=production SERVER_TYPE=user | dedup tsmserver | eval egroupname="it-service-backup-"+lower(tsmserver) | fields egroupname | append [search `lastdb("nodes")` | lookup serverinfo TSMSERVER AS tsmserver OUTPUTNEW BUILDING SERVER_TYPE SERVER_STATUS | search SERVER_STATUS=production SERVER_TYPE=user | dedup BUILDING | eval egroupname="it-service-backup-b"+BUILDING | fields egroupname] | checkegroups | where contact!="it-service-backup-notify" AND contact!="tsm-admin" AND contact!="tsm.support" | stats count AS egroup_count by egroupname | append [search `lastdb("nodes")` | lookup serverinfo TSMSERVER AS tsmserver OUTPUTNEW SERVER_TYPE SERVER_STATUS | search SERVER_STATUS=production SERVER_TYPE=user | eval CONTACT=lower(CONTACT) | where CONTACT!="tsm-admin" AND CONTACT!="tsm.support" | stats dc(CONTACT) AS tsmdb_count by tsmserver | eval egroupname="it-service-backup-"+lower(tsmserver) | fields egroupname tsmdb_count] | append [search `lastdb("nodes")` | lookup serverinfo TSMSERVER AS tsmserver | search SERVER_STATUS=production SERVER_TYPE=user | stats dc(tsmserver) AS tsmdb_count by BUILDING | eval egroupname="it-service-backup-b"+BUILDING | fields egroupname tsmdb_count] | stats sum(*_count) AS *_count by egroupname | eval "Correct?"=if('egroup_count'=='tsmdb_count', "yes", "no") | rename egroupname AS "E-group" egroup_count AS "Members in e-group" tsmdb_count AS "Contacts in TSMDB" | table "E-group" "Members in e-group" "Contacts in TSMDB" "Correct?" | search "Correct?"=no

# Alert if there are contacts we can't email
[egroups_noemail_alert]
is_visible = false
action.email.inline = 1
action.script = 1
action.script.filename = alert.py
alert.severity = 4
alert.suppress = 0
alert.track = 1
cron_schedule = 0 9 * * *
dispatch.earliest_time = -1d
dispatch.latest_time = now
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
search = | inputlookup serverinfo | search SERVER_STATUS=production SERVER_TYPE=user | eval egroupname="it-service-backup-"+lower(TSMSERVER) | checkegroups | search acceptemails!=True



# Update SLS data

[sls_avail_update]
action.email.reportServerEnabled = 0
alert.track = false
action.script = 1
action.script.filename = sls_availability.py
dispatch.earliest_time = -30m
dispatch.latest_time = now
cron_schedule = */5 * * * *
enableSched = 1
is_visible = false
search = | inputlookup serverinfo | search SERVER_STATUS=production | fields TSMSERVER | rename TSMSERVER as tsmserver | join type=outer tsmserver [search index=tsmlogs | stats count by tsmserver] | join type=outer tsmserver [search `lastdb_time("nodes", "earliest=-24h")` | stats count AS nodes sum(eval(if(LOCKED=="NO", 1,0))) AS unlocked_nodes by tsmserver] | join type=outer tsmserver [search `lastdb("drives")` | stats sum(eval(if(ONLINE=="YES", 1,0))) AS online by tsmserver] | join type=outer tsmserver [search `lastdb("status")` | fields tsmserver AVAILABILITY] | fillnull value=100 sls_value | eval sls_value=if(isnull(count), 0, sls_value) | eval sls_value=if(unlocked_nodes==0 and nodes>0 and SERVER_TYPE=user, sls_value-20, sls_value) | eval sls_value=if(online==0, sls_value-50, sls_value) | eval sls_value=if(AVAILABILITY!="ENABLED", sls_value-50, sls_value)

[sls_accounting_update]
action.email.reportServerEnabled = 0
alert.track = false
action.script = 1
action.script.filename = sls_accounting.py
dispatch.earliest_time = -24h
dispatch.latest_time = now
cron_schedule = 30 8 * * *
enableSched = 0
is_visible = false
search = `lastdb("occupancy")` | stats sum(REPORTING_MB) AS total_mb | eval sls_value=round(total_mb/1024/1024/1024, 2) | eval sls_id="total_tape" | eval sls_name="Total Data on Tape" | eval sls_type="numeric" | eval sls_unit="PB" | eval sls_goal="less" | eval sls_publish="yes" | eval sls_target=15.9 | fields sls_* | append [search `lastdb("events")` | search NODE_NAME="*" | eval onedayago=strftime(now()-86400,"%Y-%m-%d") | eval twodaysago=strftime(now()-(2*86400),"%Y-%m-%d") | where SCHEDULED_START>=twodaysago AND SCHEDULED_START<onedayago | top percentfield=sls_value STATUS | eval sls_value=round(sls_value, 2) | search STATUS="Completed" | eval sls_id="completed_schedules" | eval sls_name="Percentage of completed backup schedules" | eval sls_type="percentage" | eval sls_goal="more" | eval sls_target=80 | fields sls_*] | append [search `lastdb("nodes")` | stats count AS sls_value | eval sls_id="total_clients" | eval sls_name="Number of registered clients" | eval sls_type="numeric" | eval sls_goal="more" | eval sls_target=1 | eval sls_publish="yes" | fields sls_*]


# TSM Admin alerts

[Alert summary]
is_visible = false
action.email.inline = 1
action.run_savedsearch.trigger_actions = 0
action.summary_index._name = alerts
alert.suppress = 0
alert.track = 0
cron_schedule = * * * * *
dispatch.earliest_time = -1m@m
dispatch.latest_time = @m
enableSched = 1
realtime_schedule = 0
search = index=tsmlogs tag!=alert_ignore | eval conn=split(rtrim(if(isnotnull(tapedrive), tostring(upper(if(mvcount(tapedrive)>1, mvindex(tapedrive,0), tapedrive))) + ";", "") + if(isnotnull(tapevolume), tostring(upper(if(mvcount(tapevolume)>1, mvindex(tapevolume,0), tapevolume))) + ";", "") + if(isnotnull(session), if(mvcount(session)>1, mvindex(session,0), session) + "s;", "") + if(isnotnull(process), if(mvcount(process)>1, mvindex(process,0), process) + "p;", "") + if(mvcount(tsmcode)>1, mvindex(tsmcode,0), tsmcode), ";"), ";") | eval raw=_raw | transaction conn maxpause=2m maxevents=1000 mvlist=raw | eval event_id=md5(mvindex(raw, 0)) | mvexpand raw | eval sourcetype="tsmlogs" | fields - _raw | fields event_id tsmserver host index source sourcetype raw | collect index=alerts marker="info_search_name=alerts"

[Generic Alert: Critical]
is_visible = false
action.email.inline = 1
action.script = 1
action.script.filename = alert.py
alert.severity = 5
alert.suppress = 1
alert.suppress.period = 1m
alert.track = 1
counttype = number of events
cron_schedule = * * * * *
dispatch.earliest_time = rt-1m
dispatch.latest_time = rt
enableSched = 1
quantity = 0
relation = greater than
search = index=tsmlogs sourcetype=tsmlogs eventtype=alert_critical

[Generic Alert: High]
is_visible = false
action.email.inline = 1
action.script = 1
action.script.filename = alert.py
alert.severity = 4
alert.suppress = 0
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
enableSched = 1
quantity = 0
relation = greater than
search = index=alerts | transaction event_id | search alert=high

[Generic Alert: Medium]
is_visible = false
action.email.inline = 1
action.script = 1
action.script.filename = alert.py
alert.severity = 3
alert.suppress = 0
alert.track = 1
counttype = number of events
cron_schedule = */30 * * * *
dispatch.earliest_time = -30m
dispatch.latest_time = now
enableSched = 1
quantity = 0
relation = greater than
search = index=alerts | transaction event_id | search alert=medium alert!=high

[Generic Alert: Low]
is_visible = false
action.email.inline = 1
action.script = 1
action.script.filename = alert.py
alert.severity = 2
alert.suppress = 0
alert.track = 1
counttype = number of events
cron_schedule = 0 * * * *
dispatch.earliest_time = -1h
dispatch.latest_time = now
enableSched = 1
quantity = 0
relation = greater than
search = index=alerts | transaction event_id | search alert=low alert!=medium alert!=high

[Generic Alert: Info]
is_visible = false
action.email.inline = 1
action.script = 1
action.script.filename = alert.py
alert.severity = 1
alert.suppress = 0
alert.track = 1
counttype = number of events
cron_schedule = 0 8 * * *
dispatch.earliest_time = -1d
dispatch.latest_time = now
enableSched = 1
quantity = 0
relation = greater than
search = index=tsmlogs sourcetype=tsmlogs eventtype=alert_info | rex "dsmserv-[^ ]+: (?<msg>.*)" | eval msg=replace(msg, "\(SESSION: \d+\)$", "") | eval msg=replace(msg, "for session \d+", "for session X") | eval time=strftime(_time, "%F %T") | stats count values(tsmserver) AS Servers values(msg) AS "Sample messages" latest(time) AS "Last seen" by tsmcode | eval "Sample messages"=mvindex('Sample messages', 0, 9) | sort -count

[Uncategorized Alerts]
is_visible = false
action.email.inline = 1
action.script = 1
action.script.filename = alert.py
alert.severity = 1
alert.suppress = 0
alert.track = 1
counttype = number of events
cron_schedule = 0 8 * * *
dispatch.earliest_time = -1d
dispatch.latest_time = now
enableSched = 1
quantity = 0
relation = greater than
search = index=tsmlogs (eventtype=error OR eventtype=warning) NOT alert=* | rex "dsmserv-[^ ]+: (?<msg>.*)" | eval time=strftime(_time, "%F %T") | stats count values(tsmserver) AS Servers latest(msg) AS "Sample message" latest(time) AS "Last seen" by tsmcode | sort tsmcode
description = The following messages are not properly categorized using the alert lookup table.


# User Failed Backups notifications

[Failed backups]
is_visible = false
action.email.inline = 1
action.script = 1
action.script.filename = failed_backup.py
alert.severity = 1
alert.suppress = 0
alert.track = 1
counttype = number of events
cron_schedule = 30 8 * * *
dispatch.earliest_time = -1d
dispatch.latest_time = now
enableSched = 1
quantity = 0
relation = greater than
search = | inputlookup nodeinfo | where isnull(DEL_TIME) | lookup serverinfo TSMSERVER AS tsmserver OUTPUTNEW SERVER_TYPE SERVER_STATUS | search SERVER_STATUS=production SERVER_TYPE=user | eval CONTACT=lower(CONTACT) | join max=0 tsmserver NODE_NAME [| inputlookup scheduleinfo | fields tsmserver NODE_NAME SCHEDULE_NAME] | rename NODE_NAME AS node DOMAIN_NAME AS domain SCHEDULE_NAME AS client_schedule | eval _time=now() | lookup nodealerts tsmserver node OUTPUT alert AS ALERTS | eval ALERTS=coalesce(ALERTS, ALERTS_DEFAULT, "YES") | fields - ALERTS_DEFAULT | search ALERTS=YES | join tsmserver node domain client_schedule [| inputlookup schedulestatus | search status!=Pending status!=Started status!="In Progress" | eval _time=scheduled_start_time | fillnull value="" start_time end_time result reason | stats latest(status_time) AS status_time latest(scheduled_start_time) AS scheduled_start_time  latest(start_time) AS start_time latest(end_time) AS end_time latest(status) AS status latest(result) AS result latest(reason) AS reason max(eval(if(status="Completed", start_time, NULL))) AS completed_start_time max(eval(if(status="Completed", end_time, NULL))) AS last_completed max(eval(if(status="Completed", result, NULL))) AS completed_result max(eval(if(status="Completed", reason, NULL))) AS completed_reason by tsmserver node domain schedule | rename schedule AS client_schedule | eval days_since=(now()-last_completed)/86400] | search status!=Completed | where isnull(last_completed) OR isnull(days_since) OR days_since-0.2>BACKUP_CYCLE | sort client_schedule | eval GROUP=if(isnotnull(USER_GROUP), USER_GROUP . if(isnotnull(USER_SUBGROUP), "/".USER_SUBGROUP, ""), "") | stats first(CONTACT) AS CONTACT first(GROUP) AS GROUP list(client_schedule) AS client_schedule list(status) AS status LIST(last_completed) AS last_completed list(days_since) AS days_since max(days_since) AS max_days by tsmserver node | sort -max_days | fields - max_days | join type=outer tsmserver node [search `lastdb("filespaces")` | lookup serverinfo TSMSERVER AS tsmserver OUTPUTNEW SERVER_TYPE SERVER_STATUS | search SERVER_STATUS=production SERVER_TYPE=user | eval last_completed=round(strptime(BACKUP_END, "%F %T.000000")) | eval days_since=(now()-last_completed)/86400 | rename NODE_NAME AS node | sort 1000000 FILESPACE_NAME | eval fs=coalesce(FILESPACE_NAME,"").":".coalesce(last_completed,"").":".coalesce(days_since,"") | stats list(fs) AS fs_list by tsmserver node | eval fs_list=mvjoin(fs_list, "$;$")] | makemv delim="$;$" fs_list | append [search `lastdb("filespaces")` | lookup serverinfo TSMSERVER AS tsmserver OUTPUTNEW SERVER_TYPE SERVER_STATUS | search SERVER_STATUS=production SERVER_TYPE=user | lookup nodeinfo tsmserver NODE_NAME OUTPUTNEW ALERTS_DEFAULT BACKUP_CYCLE CONTACT USER_GROUP USER_SUBGROUP | lookup nodealerts tsmserver node AS NODE_NAME OUTPUT alert AS ALERTS | eval ALERTS=coalesce(ALERTS, ALERTS_DEFAULT, "YES") | fields - ALERTS_DEFAULT | search ALERTS=YES | join type=outer tsmserver NODE_NAME [| inputlookup scheduleinfo | eval IS_BASESNAPDIFF=if(match(lower(OPTIONS), "-createnewbase=yes"), 1, 0) | eval SNAPDIFF_CYCLE=PERIOD*case(PERUNITS=="HOURS", 1/24, PERUNITS=="DAYS", 1, PERUNITS=="WEEKS", 7, PERUNITS=="MONTHS", 31, PERUNITS=="YEARS", 365) | search IS_BASESNAPDIFF=1 | fields tsmserver NODE_NAME SNAPDIFF_CYCLE] | eval BACKUP_CYCLE=if(isnotnull(SNAPDIFF_CYCLE), SNAPDIFF_CYCLE, BACKUP_CYCLE) | eval CONTACT=lower(CONTACT) | eval GROUP=if(isnotnull(USER_GROUP), USER_GROUP . if(isnotnull(USER_SUBGROUP), "/".USER_SUBGROUP, ""), "") | eval last_completed=round(strptime(BACKUP_END, "%F %T.000000")) | eval days_since=(now()-last_completed)/86400 | where days_since-0.2>BACKUP_CYCLE | sort 1000000 FILESPACE_NAME | rename NODE_NAME AS node | stats first(CONTACT) AS CONTACT first(GROUP) AS GROUP list(FILESPACE_NAME) AS FILESPACES LIST(last_completed) AS last_completed list(days_since) AS days_since max(days_since) AS max_days by tsmserver node | sort -max_days | fields - max_days]


# Expired or Retired nodes

[retire_nodes_alert]
is_visible = false
action.email.inline = 1
action.script = 1
action.script.filename = retire_nodes.py
alert.severity = 1
alert.suppress = 0
alert.track = 1
cron_schedule = 30 8 * * *
dispatch.earliest_time = -1d
dispatch.latest_time = now
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
search = | inputlookup nodeinfo | eval retire=if(now() > RETIRE_TIME, 1, 0) | eval days_to_expire=if(isnotnull(EXPIRE_TIME), round((EXPIRE_TIME-strptime(strftime(now(), "%F")+" 00:00:00 UTC", "%F %T %Z"))/86400), NULL) | eval GROUP=if(isnotnull(USER_GROUP), USER_GROUP . if(isnotnull(USER_SUBGROUP), "/".USER_SUBGROUP, ""), "") | where isnull(DEL_TIME) AND isnull(RETIRE_TIME) AND (retire=1 OR days_to_expire<=30) | sort days_to_expire NODE_NAME

# Alerts for various sorts of problems

[Unaccessible volumes]
is_visible = false
action.email.inline = 1
action.script = 1
action.script.filename = alert.py
alert.suppress = 0
alert.severity = 2
alert.track = 1
cron_schedule = 0 9 * * *
dispatch.earliest_time = -24h
dispatch.latest_time = now
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
search = (ACCESS!=READWRITE OR STATUS=OFFLINE) `lastdb("volumes")` | table tsmserver DEVCLASS_NAME VOLUME_NAME STGPOOL_NAME ACCESS STATUS | sort tsmserver VOLUME_NAME
description = The following volumes are not writable:

[Unregistered nodes]
is_visible = false
action.email.inline = 1
action.script = 1
action.script.filename = alert.py
alert.suppress = 0
alert.severity = 2
alert.track = 1
cron_schedule = 0 9 * * *
dispatch.earliest_time = -24h
dispatch.latest_time = now
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
search = index=tsmlogs tsmcode="ANR0422W" | stats count by tsmserver node | search count > 10
description = The following unregistered node(s) tried to log in to a TSM server:

[Duplicate drive serial numbers]
is_visible = false
action.email.inline = 1
action.script = 1
action.script.filename = alert.py
alert.suppress = 0
alert.severity = 5
alert.track = 1
cron_schedule = 0 9 * * *
dispatch.earliest_time = -1h
dispatch.latest_time = now
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
search = `lastdb("drives")` | dedup _time DRIVE_NAME | stats count list(DRIVE_NAME) AS DRIVE_NAME list(LIBRARY_NAME) AS LIBRARY_NAME  by DRIVE_SERIAL | where count>1
description = The following drives share the same serial number, which is a REALLY BAD THING.

[Tape volume inconsistencies]
is_visible = false
action.email.inline = 1
action.script = 1
action.script.filename = alert.py
alert.suppress = 0
alert.severity = 5
alert.track = 1
cron_schedule = 0 9 * * *
dispatch.earliest_time = -2h
dispatch.latest_time = now
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
search = `lastdb("libvolumes")` | join type=outer max=0 VOLUME_NAME [search DEVCLASS_NAME!=DISK DEVCLASS_NAME!=FILE `lastdb("volumes")` | rename tsmserver AS TSMSERVER | fields - STATUS] | join type=outer VOLUME_NAME [search VOLUME_NAME=I* `lastdb("volhistory")` | eval _time=strptime(DATE_TIME, "%F %T.000000") | stats latest(TYPE) AS TYPE by VOLUME_NAME | search TYPE=BACKUPFULL OR TYPE=BACKUPINCR | eval LAST_USE="DbBackup" | fields VOLUME_NAME LAST_USE] | fillnull value="" TSMSERVER OWNER LAST_USE | stats count list(TSMSERVER) AS TSMSERVER values(LIBRARY_NAME) AS LIBRARY_NAME values(OWNER) AS OWNER values(STATUS) AS STATUS list(STGPOOL_NAME) AS STGPOOL_NAME values(LAST_USE) AS LAST_USE by VOLUME_NAME | where count>1 OR (mvindex(TSMSERVER, 0)!=mvindex(OWNER, 0) AND mvindex(STATUS, 0)="Private" AND mvindex(LAST_USE, 0)!="DbBackup") OR (mvindex(TSMSERVER, 0)!=mvindex(OWNER, 0) AND mvindex(STATUS, 0)="Scratch") OR (mvindex(LAST_USE, 0)="DbBackup" AND mvindex(TSMSERVER, 0)!="") | rename LIBRARY_NAME AS Library VOLUME_NAME AS Volume OWNER AS "Owner (Lib. Manager)" STATUS AS Status LAST_USE AS "Last Usage (if known)" TSMSERVER AS Owner STGPOOL_NAME AS "Storage Pool" | table Library Volume "Owner (Lib. Manager)" Status "Last Usage (if known)" Owner "Storage Pool" | sort Library Volume
description = The following tapes are in an inconsistent state (two servers think they own the same tape, a server doesn't know about a tape it's supposed to own, a server thinks it owns a scratch tape, etc.). All of these issues need to be fixed urgently.

[TSM server started]
is_visible = false
action.email.inline = 1
action.script = 1
action.script.filename = alert.py
alert.suppress = 0
alert.severity = 3
alert.track = 1
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
search = index=tsmlogs tsmcode=ANR0916I | eval time=strftime(_time, "%F %T") | sort _time | table time tsmserver
description = The following TSM server(s) just started, hopefully intentionally...

[Servers not sending data]
is_visible = false
action.email.inline = 1
action.script = 1
action.script.filename = alert.py
alert.suppress = 0
alert.severity = 5
alert.track = 1
alert.suppress = 1
alert.suppress.period = 1h
alert.digest_mode = true
alert.suppress.fields = Host
cron_schedule = */5 * * * *
dispatch.earliest_time = -30m
dispatch.latest_time = now
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
search = | inputlookup serverinfo | search SERVER_STATUS=production | join HOST [| metadata index=tsmlogs type=hosts | rename host AS HOST recentTime AS recentTime_tsmlogs | fields HOST recentTime_tsmlogs] | join HOST [| metadata index=lemon type=hosts | rename host AS HOST recentTime AS recentTime_lemon | fields HOST recentTime_lemon] | eval age_tsmlogs=now()-recentTime_tsmlogs | eval age_lemon=now()-recentTime_lemon | where age_tsmlogs > 600 OR age_lemon > 800 | convert ctime(recentTime_*) | rename HOST AS Host recentTime_lemon AS "Last Lemon event" recentTime_tsmlogs AS "Last tsmlogs event" age_lemon AS "Seconds since last Lemon event"  age_tsmlogs AS "Seconds since last tsmlogs event" | table Host "Last tsmlogs event" "Seconds since last tsmlogs event" "Last Lemon event" "Seconds since last Lemon event"
description = The following server(s) aren't sending any data to Druid:

[Hanging server sessions]
is_visible = false
action.email.inline = 1
action.script = 1
action.script.filename = alert.py
alert.suppress = 0
alert.severity = 3
alert.track = 1
cron_schedule = 0 * * * *
dispatch.earliest_time = -15m
dispatch.latest_time = now
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
search = SESSION_TYPE=Server `session_info` | eval START_TIME=replace(START_TIME, "\.000000$", "") | eval duration=now()-strptime(START_TIME, "%Y-%m-%d %H:%M:%S") | search duration>10800 | eval length=tostring(duration, "duration") | table START_TIME tsmserver CLIENT_NAME SESSION_ID STATE state length
description = The following server sessions are hanging. This may indicate a server waiting to mount a drive for too long.

[Hanging server processes]
is_visible = false
action.email.inline = 1
action.script = 1
action.script.filename = alert.py
alert.suppress = 0
alert.severity = 3
alert.track = 1
cron_schedule = 0 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
search = PROCESS="Migration" OR PROCESS="Space Reclamation" `tsmdb("processes")` | rex field=STATUS "Waiting for (?<what>.*) (?<volume>I\d{5}|/[/\w\_\-\.]+\w) \((?<wait_time>\d+) seconds\)\." | where wait_time>7200 | join tsmserver volume type=outer [search `session_info` | search volume="*" | fields tsmserver volume CLIENT_NAME SESSION_ID] | sort tsmserver PROCESS_NUM | convert timeformat="%kh %Mm %Ss" ctime(wait_time) | rename tsmserver AS Server PROCESS AS Process PROCESS_NUM AS "Process #" START_TIME AS "Start time" STATUS AS Status wait_time AS "Wait time" CLIENT_NAME AS "Blocked by" SESSION_ID AS "Session #" | table Server Process "Process #" "Start time" "Wait time" "Blocked by" "Session #" Status
description = The following server processes look like they're stuck. This is probably happening because a client is taking too long to back up.

[Missed TSM database backups]
is_visible = false
action.email.inline = 1
action.script = 1
action.script.filename = alert.py
alert.digest_mode = True
auto_summarize.dispatch.earliest_time = -1d@h
alert.suppress = 1
alert.suppress.period = 3h
alert.severity = 3
alert.track = 1
cron_schedule = 0 9-23 * * *
dispatch.earliest_time = -2h
dispatch.latest_time = now
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
search = `lastdb("db")` | eval days_since_db_backup=floor((_time-strptime(LAST_BACKUP_DATE, "%Y-%m-%d %H:%M:%S"))/86400) | where days_since_db_backup > 0 | table tsmserver LAST_BACKUP_DATE days_since_db_backup
description = The following nodes haven't backed up their database on schedule.

[Flapping port]
is_visible = false
action.email.inline = 1
action.script = 1
action.script.filename = alert.py
alert.severity = 4
alert.suppress = 0
alert.track = 1
cron_schedule = 0 * * * *
dispatch.earliest_time = -1h
dispatch.latest_time = now
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
search = index=tsmfcs | transaction port startswith="logged out" endswith="logged into" | search duration<5 | eval port_wwn=replace(lower(portwwn), ":", "") | join type=outer port_wwn [| inputlookup driveinfo | makemv DRIVE_WWNS | mvexpand DRIVE_WWNS | rename DRIVE_WWNS AS port_wwn DRIVE_NAME AS device | fields port_wwn device] | join type=outer port_wwn [| inputlookup serverinfo | makemv HOST_WWNS | mvexpand HOST_WWNS | rename HOST_WWNS AS port_wwn HOST AS device | fields port_wwn device] | stats count latest(device) AS device latest(port_wwn) AS port_wwn by host,port | rename host AS Switch port AS Port port_wwn AS "Device WWN" device AS "Device Name" count as "Flaps in last hour" | table Switch Port "Device Name" "Device WWN" "Flaps in last hour"
description = The following ports are flapping (disconnecting and reconnecting rapidly). This generally means there's a problem with the device.

# User alerts
[User Alert: Invalid Password]
is_visible = false
action.email.inline = 1
action.script = 1
action.script.filename = user_alert.py
alert.suppress = 0
alert.severity = 3
alert.track = 1
cron_schedule = 0 * * * *
dispatch.earliest_time = -1h
dispatch.latest_time = now
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
search = index=tsmlogs [search index=tsmlogs tsmcode=ANR0424W | fields tsmserver session | format] tsmcode=ANR0406I | rex "Tcp/Ip (?<remote>[^(]+)\(" | lookup nodeinfo tsmserver NODE_NAME AS node OUTPUTNEW CONTACT | dedup _raw | sort - _time | table _time tsmserver node CONTACT remote
description = Unauthorized access attempts have been detected.
